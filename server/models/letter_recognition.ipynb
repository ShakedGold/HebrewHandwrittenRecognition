{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### path = data/dataset\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m ds \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msivan22/hebrew-handwritten-characters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# ds = load_dataset(\"sivan22/hebrew-handwritten-characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 125)\n",
      "(40, 40)\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# this cell is for testing\n",
    "\n",
    "#open an image file from the dataset\n",
    "img = Image.open(\"../data/dataset/TRAIN/0/0_1.png\")\n",
    "\n",
    "#display the image\n",
    "# img.show()\n",
    "\n",
    "#show image pixels\n",
    "print(img.size)\n",
    "\n",
    "#resize image to 40 by 40 pixels\n",
    "img = img.resize((40, 40))\n",
    "print(img.size)\n",
    "img.show()\n",
    "\n",
    "\n",
    "#convert image to rgba and print each pixel\n",
    "img = img.convert('RGBA')\n",
    "\n",
    "#get the pixel values of the image\n",
    "pixels = list(img.getdata())\n",
    "binary_array = []\n",
    "for pixel in pixels:\n",
    "    if pixel[0] ==  255 and pixel[1] == 255 and pixel[2] == 225:\n",
    "        binary_array.append(0)\n",
    "    else:\n",
    "        binary_array.append(1)\n",
    "\n",
    "#print all the non 0 pixels\n",
    "print(binary_array)\n",
    "\n",
    "#convert the binary array to an image\n",
    "img = Image.new('1', (40, 40))\n",
    "img.putdata(binary_array)\n",
    "img.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 125)\n",
      "(40, 40)\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# this cell is for testing\n",
    "\n",
    "#open an image file from the dataset\n",
    "img = Image.open(\"../data/dataset/TRAIN/0/0_1.png\")\n",
    "\n",
    "#display the image\n",
    "# img.show()\n",
    "\n",
    "#show image pixels\n",
    "print(img.size)\n",
    "img.show()\n",
    "#resize image to 40 by 40 pixels\n",
    "img = img.resize((40, 40))\n",
    "print(img.size)\n",
    "img.show()\n",
    "\n",
    "\n",
    "#convert image to rgba and print each pixel\n",
    "img = img.convert('RGBA')\n",
    "\n",
    "#get the pixel values of the image\n",
    "pixels = list(img.getdata())\n",
    "binary_array = []\n",
    "for pixel in pixels:\n",
    "    if pixel[0] >= 128 and pixel[1] >= 128 and pixel[2] >= 128:\n",
    "        binary_array.append(1)\n",
    "    else:\n",
    "        binary_array.append(0)\n",
    "\n",
    "#print all the non 0 pixels\n",
    "print(binary_array)\n",
    "\n",
    "#convert the binary array to an image\n",
    "img = Image.new('1', (40, 40))\n",
    "img.putdata(binary_array)\n",
    "img.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method to convert img to arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_to_binary_array(img):\n",
    "    #convert image to rgba\n",
    "    img = img.resize((100, 100))  \n",
    "    img = img.convert('RGBA')\n",
    "\n",
    "    #get the pixel values of the image\n",
    "    pixels = list(img.getdata())\n",
    "    binary_array = []\n",
    "    for pixel in pixels:\n",
    "        if pixel[0] >= 128 and pixel[1] >= 128 and pixel[2] >= 128:\n",
    "            binary_array.append(1)\n",
    "        else:\n",
    "            binary_array.append(0)\n",
    "    return binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create training and testing arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: 0\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_1.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_10.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_100.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_101.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_102.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_103.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_104.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_105.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_106.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_107.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_108.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_109.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_11.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_110.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_111.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_112.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_113.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_114.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_115.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_116.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_117.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_118.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_119.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_12.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_120.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_121.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_122.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_123.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_124.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_125.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_126.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_127.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_128.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_129.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_13.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_130.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_131.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_132.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_133.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_134.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_135.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_136.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_137.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_138.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_139.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_14.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_140.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_141.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_142.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_143.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_144.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_145.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_146.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_147.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_148.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_149.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_15.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_16.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_17.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_18.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_19.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_2.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_20.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_21.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_22.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_23.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_24.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_25.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_26.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_27.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_28.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_29.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_3.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_30.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_31.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_32.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_33.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_34.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_35.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_36.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_37.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_38.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_39.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_4.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_40.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_41.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_42.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_43.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_44.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_45.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_46.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_47.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_48.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_49.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_5.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_50.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_51.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_52.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_53.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_54.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_55.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_56.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_57.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_58.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_59.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_6.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_60.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_61.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_62.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_63.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_64.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_65.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_66.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_67.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_68.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_69.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_7.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_70.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_71.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_72.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_73.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_74.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_75.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_76.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_77.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_78.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_79.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_8.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_80.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_81.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_82.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_83.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_84.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_85.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_86.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_87.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_88.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_89.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_9.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_90.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_91.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_92.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_93.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_94.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_95.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_96.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_97.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_98.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/0\\0_99.png: too many data entries\n",
      "Processing folder: 1\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_1.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_10.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_100.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_101.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_102.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_103.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_104.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_105.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_106.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_107.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_108.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_109.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_11.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_110.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_111.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_112.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_113.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_114.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_115.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_116.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_117.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_118.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_119.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_12.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_120.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_121.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_122.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_123.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_124.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_125.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_126.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_127.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_128.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_129.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_13.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_130.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_131.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_132.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_133.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_134.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_135.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_136.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_137.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_138.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_139.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_14.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_140.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_141.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_142.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_143.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_144.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_145.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_146.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_147.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_148.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_149.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_15.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_16.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_17.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_18.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_19.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_2.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_20.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_21.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_22.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_23.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_24.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_25.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_26.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_27.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_28.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_29.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_3.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_30.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_31.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_32.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_33.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_34.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_35.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_36.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_37.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_38.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_39.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_4.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_40.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_41.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_42.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_43.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_44.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_45.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_46.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_47.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_48.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_49.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_5.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_50.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_51.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_52.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_53.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_54.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_55.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_56.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_57.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_58.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_59.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_6.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_60.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_61.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_62.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_63.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_64.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_65.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_66.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_67.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_68.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_69.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_7.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_70.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_71.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_72.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_73.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_74.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_75.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_76.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_77.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_78.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_79.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_8.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_80.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_81.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_82.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_83.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_84.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_85.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_86.png: too many data entries\n",
      "Error processing file ../data/dataset/TRAIN/1\\1_87.png: too many data entries\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path):\n\u001b[0;32m     16\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file)\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m             img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(file_path)\n",
      "File \u001b[1;32m<frozen genericpath>:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "min_width = 100\n",
    "min_height = 100\n",
    "\n",
    "path = \"../data/dataset/TRAIN/\"\n",
    "for folder in os.listdir(path):\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    if folder == \"27\":\n",
    "        continue\n",
    "    print(f\"Processing folder: {folder}\")\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "\n",
    "                # check minimum width and height\n",
    "                if img.width < min_width or img.height < min_height:\n",
    "                    min_width = img.width\n",
    "                    min_height = img.height\n",
    "\n",
    "                binary_array = convert_img_to_binary_array(img)\n",
    "\n",
    "                pixels = [ p * 255 for p in binary_array ]\n",
    "\n",
    "                # save to a new image\n",
    "                img = Image.new('L', (100, 100))\n",
    "                img.putdata(pixels)\n",
    "\n",
    "                # create folder if it doesn't exist\n",
    "                if not os.path.exists(f\"../data/dataset/TRAIN_BINARY/{folder}\"):\n",
    "                    os.makedirs(f\"../data/dataset/TRAIN_BINARY/{folder}\")\n",
    "                \n",
    "                img.save(f\"../data/dataset/TRAIN_BINARY/{folder}/{file}\")\n",
    "\n",
    "                X_train.append(binary_array)\n",
    "                y_train.append(int(folder))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "print(f\"Minimum width: {min_width}, Minimum height: {min_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: 0\n",
      "Processing folder: 1\n",
      "Processing folder: 10\n",
      "Processing folder: 11\n",
      "Processing folder: 12\n",
      "Processing folder: 13\n",
      "Processing folder: 14\n",
      "Processing folder: 15\n",
      "Processing folder: 16\n",
      "Processing folder: 17\n",
      "Processing folder: 18\n",
      "Processing folder: 19\n",
      "Processing folder: 2\n",
      "Processing folder: 20\n",
      "Processing folder: 21\n",
      "Processing folder: 22\n",
      "Processing folder: 23\n",
      "Processing folder: 24\n",
      "Processing folder: 25\n",
      "Processing folder: 26\n",
      "Processing folder: 3\n",
      "Processing folder: 4\n",
      "Processing folder: 5\n",
      "Processing folder: 6\n",
      "Processing folder: 7\n",
      "Processing folder: 8\n",
      "Processing folder: 9\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "path = \"../data/dataset/TEST/\"\n",
    "for folder in os.listdir(path):\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    if folder == \"27\":\n",
    "        continue\n",
    "    print(f\"Processing folder: {folder}\")\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                binary_array = convert_img_to_binary_array(img)\n",
    "                X_test.append(binary_array)\n",
    "                y_test.append(int(folder))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4058\n",
      "Test size: 1015\n"
     ]
    }
   ],
   "source": [
    "# # connect train and test data\n",
    "X = X_train + X_test\n",
    "y = y_train + y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Test size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CalibratedClassifierCV(cv=5, estimator=LinearSVC())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CalibratedClassifierCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.calibration.CalibratedClassifierCV.html\">?<span>Documentation for CalibratedClassifierCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CalibratedClassifierCV(cv=5, estimator=LinearSVC())</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LinearSVC</label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CalibratedClassifierCV(cv=5, estimator=LinearSVC())"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm_model = svm.SVC(probability=True)\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "model = svm.LinearSVC()\n",
    "svm_model = CalibratedClassifierCV(model, cv=5, method='sigmoid')\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.97770666e-02 7.34095844e-03 4.81115450e-02 ... 3.95113905e-02\n",
      "  6.57683618e-02 6.39607554e-03]\n",
      " [2.40006428e-03 1.20886756e-03 1.79228058e-01 ... 1.61636914e-05\n",
      "  5.04279378e-01 5.75120071e-04]\n",
      " [6.02299080e-01 1.01560495e-02 8.95812152e-02 ... 3.82510978e-04\n",
      "  1.41980279e-02 4.85394154e-05]\n",
      " ...\n",
      " [2.22150093e-03 4.26245413e-02 3.87749182e-03 ... 7.36488565e-03\n",
      "  1.98935295e-02 3.58497571e-02]\n",
      " [1.29328608e-02 2.63229320e-03 1.79205872e-04 ... 2.15488258e-02\n",
      "  4.32957196e-02 5.15534612e-05]\n",
      " [6.03496185e-02 1.07232219e-01 6.53145189e-04 ... 2.08449213e-03\n",
      "  8.12840379e-02 2.71399430e-05]]\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm_model.predict_proba(X_test)\n",
    "print(svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.039777  0.007341  0.048112  0.093581  0.063427  0.011737  0.163935   \n",
      "1  0.002400  0.001209  0.179228  0.001184  0.003049  0.001747  0.000040   \n",
      "2  0.602299  0.010156  0.089581  0.000566  0.001722  0.000222  0.011274   \n",
      "3  0.001098  0.003987  0.010627  0.027967  0.003310  0.489614  0.093625   \n",
      "4  0.002363  0.006455  0.000064  0.004813  0.016255  0.002748  0.017534   \n",
      "5  0.000500  0.027042  0.000103  0.007084  0.063479  0.004867  0.001498   \n",
      "6  0.091787  0.042823  0.001176  0.015748  0.001863  0.005271  0.087392   \n",
      "7  0.001526  0.012067  0.000940  0.029080  0.013930  0.002361  0.000247   \n",
      "8  0.013121  0.006001  0.084214  0.005309  0.000670  0.099493  0.147741   \n",
      "9  0.019746  0.078100  0.006859  0.018401  0.092619  0.002187  0.021563   \n",
      "\n",
      "          7         8         9  ...        22        23        24        25  \\\n",
      "0  0.012981  0.003480  0.092406  ...  0.010403  0.008713  0.039511  0.065768   \n",
      "1  0.000399  0.008480  0.000091  ...  0.006433  0.000141  0.000016  0.504279   \n",
      "2  0.005815  0.115469  0.000203  ...  0.045086  0.004048  0.000383  0.014198   \n",
      "3  0.000019  0.000390  0.048776  ...  0.006614  0.000013  0.000874  0.024318   \n",
      "4  0.003092  0.002037  0.001823  ...  0.038135  0.003273  0.005253  0.006112   \n",
      "5  0.340454  0.000300  0.003597  ...  0.034021  0.017420  0.327857  0.020481   \n",
      "6  0.331012  0.062148  0.002560  ...  0.031375  0.010137  0.005437  0.034459   \n",
      "7  0.147435  0.003516  0.000409  ...  0.101652  0.063218  0.019986  0.106144   \n",
      "8  0.000438  0.148677  0.001602  ...  0.006423  0.000106  0.003973  0.015298   \n",
      "9  0.109783  0.001192  0.004034  ...  0.014636  0.025498  0.013152  0.024347   \n",
      "\n",
      "         26  actual  predicted  probability  actual_probability  correct  \n",
      "0  0.006396      19          6     0.163935            0.013805    False  \n",
      "1  0.000575      25         25     0.504279            0.504279     True  \n",
      "2  0.000049       0          0     0.602299            0.602299     True  \n",
      "3  0.000636       5          5     0.489614            0.489614     True  \n",
      "4  0.528317      26         26     0.528317            0.528317     True  \n",
      "5  0.030473      24          7     0.340454            0.327857    False  \n",
      "6  0.038509       0          7     0.331012            0.091787    False  \n",
      "7  0.000070      20         11     0.204867            0.060174    False  \n",
      "8  0.007056      15         10     0.170694            0.081322    False  \n",
      "9  0.130636      26         15     0.139852            0.130636    False  \n",
      "\n",
      "[10 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# for each prediction create a dictionary with the probabilities and their label for each probability\n",
    "svm_predictions_dict = []\n",
    "for i in range(len(svm_predictions)):\n",
    "    prediction = svm_predictions[i]\n",
    "    prediction_dict = {}\n",
    "    for j in range(len(prediction)):\n",
    "        prediction_dict[j] = prediction[j]\n",
    "    svm_predictions_dict.append(prediction_dict)\n",
    "\n",
    "# create a dataframe from the predictions\n",
    "svm_predictions_df = pd.DataFrame(svm_predictions_dict)\n",
    "\n",
    "# add the actual labels to the dataframe\n",
    "svm_predictions_df['actual'] = y_test\n",
    "\n",
    "# add the predicted labels to the dataframe\n",
    "svm_predictions_df['predicted'] = svm_model.predict(X_test)\n",
    "\n",
    "# add the probabilities of the predicted label to the dataframe\n",
    "svm_predictions_df['probability'] = svm_predictions_df.apply(lambda x: x[x['predicted']], axis=1)\n",
    "\n",
    "# add the probabilities of the actual label to the dataframe\n",
    "svm_predictions_df['actual_probability'] = svm_predictions_df.apply(lambda x: x[x['actual']], axis=1)\n",
    "\n",
    "# add a column to the dataframe to indicate if the prediction was correct\n",
    "svm_predictions_df['correct'] = svm_predictions_df['actual'] == svm_predictions_df['predicted']\n",
    "\n",
    "# show top 10\n",
    "print(svm_predictions_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5684729064039409\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions_df['predicted'])\n",
    "\n",
    "print(f\"SVM Accuracy: {svm_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import pickle\n",
    "with open('../models/svm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the accuracies of the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7497536945812808\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "# print(\"KNN Accuracy:\", knn_accuracy)\n",
    "# print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "# print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "# print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Algorithm  Accuracy  Precision    Recall  F1-Score\n",
      "0            SVM  0.749754   0.760278  0.749754  0.748954\n",
      "1            KNN  0.566502   0.613491  0.566502  0.556145\n",
      "2  Decision Tree  0.414778   0.415872  0.414778  0.411652\n",
      "3  Random Forest  0.689655   0.696677  0.689655  0.684458\n",
      "4    Naive Bayes  0.348768   0.388866  0.348768  0.310005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\נתניה\\HebrewHandwrittenRecognition\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "\n",
    "svm_precision = precision_score(y_test, svm_predictions, average='weighted')\n",
    "knn_precision = precision_score(y_test, knn_predictions, average='weighted')\n",
    "dt_precision = precision_score(y_test, dt_predictions, average='weighted')\n",
    "rf_precision = precision_score(y_test, rf_predictions, average='weighted')\n",
    "nb_precision = precision_score(y_test, nb_predictions, average='weighted')\n",
    "\n",
    "svm_recall = recall_score(y_test, svm_predictions, average='weighted')\n",
    "knn_recall = recall_score(y_test, knn_predictions, average='weighted')\n",
    "dt_recall = recall_score(y_test, dt_predictions, average='weighted')\n",
    "rf_recall = recall_score(y_test, rf_predictions, average='weighted')\n",
    "nb_recall = recall_score(y_test, nb_predictions, average='weighted')\n",
    "\n",
    "svm_f1 = f1_score(y_test, svm_predictions, average='weighted')\n",
    "knn_f1 = f1_score(y_test, knn_predictions, average='weighted')\n",
    "dt_f1 = f1_score(y_test, dt_predictions, average='weighted')\n",
    "rf_f1 = f1_score(y_test, rf_predictions, average='weighted')\n",
    "nb_f1 = f1_score(y_test, nb_predictions, average='weighted')\n",
    "\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Algorithm': ['SVM', 'KNN', 'Decision Tree', 'Random Forest', 'Naive Bayes'],\n",
    "    'Accuracy': [svm_accuracy, knn_accuracy, dt_accuracy, rf_accuracy, nb_accuracy],\n",
    "    'Precision': [svm_precision, knn_precision, dt_precision, rf_precision, nb_precision],\n",
    "    'Recall': [svm_recall, knn_recall, dt_recall, rf_recall, nb_recall],\n",
    "    'F1-Score': [svm_f1, knn_f1, dt_f1, rf_f1, nb_f1]\n",
    "})\n",
    "\n",
    "print(performance_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a manual set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: 0\n",
      "Processing folder: 1\n",
      "Processing folder: 2\n",
      "Processing folder: 3\n",
      "Processing folder: 4\n"
     ]
    }
   ],
   "source": [
    "X_manual = []\n",
    "y_manual = []\n",
    "\n",
    "path = \"../data/dataset/manualTest/\"\n",
    "for folder in os.listdir(path):\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    if folder == \"27\":\n",
    "        continue\n",
    "    print(f\"Processing folder: {folder}\")\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                binary_array = convert_img_to_binary_array(img)\n",
    "                X_manual.append(binary_array)\n",
    "                y_manual.append(int(folder))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_manual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./svm_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      4\u001b[0m     svm_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m----> 5\u001b[0m manual_predictions \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_manual\u001b[49m)\n\u001b[0;32m      6\u001b[0m manual_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_manual, manual_predictions)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mManual Test Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, manual_accuracy)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_manual' is not defined"
     ]
    }
   ],
   "source": [
    "#show manuak test accuracy\n",
    "import pickle\n",
    "with open('./svm_model.sav', 'rb') as file:\n",
    "    svm_model = pickle.load(file)\n",
    "manual_predictions = svm_model.predict(X_manual)\n",
    "manual_accuracy = accuracy_score(y_manual, manual_predictions)\n",
    "print(\"Manual Test Accuracy:\", manual_accuracy)\n",
    "print(\"Manual Test Predictions:\", manual_predictions)\n",
    "print(\"Manual Test Actual:\", y_manual)\n",
    "\n",
    "#predict the 4th image\n",
    "img = Image.open(\"../data/dataset/manualTest/1/1_01.png\")\n",
    "img.show()\n",
    "binary_array = convert_img_to_binary_array(img)\n",
    "prediction = svm_model.predict([binary_array])[0]\n",
    "print(\"Prediction:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
